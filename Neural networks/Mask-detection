{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'Train'\n",
    "val_dir = 'Validation'\n",
    "test_dir = 'Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "IMG_SHAPE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_gen = ImageDataGenerator(rescale=1./255,  zoom_range=0.1)\n",
    "\n",
    "train_data_gen = image_gen.flow_from_directory(batch_size=batch_size,\n",
    "                                                directory=train_dir,\n",
    "                                                shuffle=True,\n",
    "                                                target_size=(IMG_SHAPE,IMG_SHAPE),\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_gen_val = ImageDataGenerator(rescale=1./255,)\n",
    "\n",
    "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
    "                                                directory=val_dir,\n",
    "                                                target_size=(IMG_SHAPE,IMG_SHAPE),\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 992 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_gen_test = ImageDataGenerator(rescale=1./255,)\n",
    "\n",
    "test_data_gen = image_gen_test.flow_from_directory(batch_size=batch_size,\n",
    "                                                directory=test_dir,\n",
    "                                                target_size=(IMG_SHAPE,IMG_SHAPE),\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "URL = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "feature_extractor = hub.KerasLayer(URL,\n",
    "                                   input_shape=(IMG_SHAPE, IMG_SHAPE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 1280)              2257984   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 2562      \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,562\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  feature_extractor,\n",
    "  tf.keras.layers.Dense(2,activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "157/157 [==============================] - 85s 513ms/step - loss: 0.2119 - accuracy: 0.9362 - val_loss: 0.0597 - val_accuracy: 0.9862\n",
      "Epoch 2/15\n",
      "157/157 [==============================] - 79s 504ms/step - loss: 0.0333 - accuracy: 0.9915 - val_loss: 0.0383 - val_accuracy: 0.9925\n",
      "Epoch 3/15\n",
      "157/157 [==============================] - 79s 502ms/step - loss: 0.0205 - accuracy: 0.9959 - val_loss: 0.0322 - val_accuracy: 0.9937\n",
      "Epoch 4/15\n",
      "157/157 [==============================] - 79s 504ms/step - loss: 0.0147 - accuracy: 0.9966 - val_loss: 0.0314 - val_accuracy: 0.9937\n",
      "Epoch 5/15\n",
      "157/157 [==============================] - 80s 509ms/step - loss: 0.0157 - accuracy: 0.9956 - val_loss: 0.0276 - val_accuracy: 0.9937\n",
      "Epoch 6/15\n",
      "157/157 [==============================] - 79s 504ms/step - loss: 0.0112 - accuracy: 0.9980 - val_loss: 0.0216 - val_accuracy: 0.9950\n",
      "Epoch 7/15\n",
      "157/157 [==============================] - 79s 501ms/step - loss: 0.0087 - accuracy: 0.9978 - val_loss: 0.0247 - val_accuracy: 0.9950\n",
      "Epoch 8/15\n",
      "157/157 [==============================] - 78s 497ms/step - loss: 0.0091 - accuracy: 0.9975 - val_loss: 0.0220 - val_accuracy: 0.9950\n",
      "Epoch 9/15\n",
      "157/157 [==============================] - 79s 501ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0244 - val_accuracy: 0.9950\n",
      "Epoch 10/15\n",
      "157/157 [==============================] - 78s 498ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 0.0191 - val_accuracy: 0.9950\n",
      "Epoch 11/15\n",
      "157/157 [==============================] - 78s 498ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.0190 - val_accuracy: 0.9950\n",
      "Epoch 12/15\n",
      "157/157 [==============================] - 78s 497ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0218 - val_accuracy: 0.9950\n",
      "Epoch 13/15\n",
      "157/157 [==============================] - 79s 500ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0185 - val_accuracy: 0.9950\n",
      "Epoch 14/15\n",
      "157/157 [==============================] - 78s 498ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.0223 - val_accuracy: 0.9950\n",
      "Epoch 15/15\n",
      "157/157 [==============================] - 78s 497ms/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 0.0195 - val_accuracy: 0.9950\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=int(np.ceil(train_data_gen.n / float(batch_size))),\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=int(np.ceil(val_data_gen.n / float(batch_size)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.019548997282981873, 0.9950000047683716]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_data_gen, batch_size=64, verbose=0, steps=(np.ceil(val_data_gen.n / float(batch_size))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01482042483985424, 0.9939516186714172]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_data_gen, batch_size=64, verbose=0, steps=(np.ceil(test_data_gen.n / float(batch_size))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_mask.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'teste.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.keras.preprocessing.image.load_img(path,target_size=(IMG_SHAPE,IMG_SHAPE))\n",
    "input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "predictions = model.predict(input_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classes = np.array(list(train_data_gen.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['WithMask', 'WithoutMask'], dtype='<U11')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WithMask'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[np.argmax(predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
